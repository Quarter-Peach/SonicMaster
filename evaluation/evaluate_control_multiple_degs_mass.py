
import argparse
import pyroomacoustics as pra

import json
import os
from pathlib import Path
from tqdm import tqdm
import soundfile as sf
import numpy as np
import librosa
from collections import defaultdict
from scipy.spatial.distance import cosine, euclidean
from scipy.signal import stft

import csv
import pandas as pd



# === CONFIG ===
SR = 44100
fs = 44100
sr = 44100
DEGRADATION_GROUPS = {
    "EQ": ["xband", "mic", "bright", "dark", "airy", "boom", "clarity", "mud", "warm", "vocal"],
    "Dynamics": ["comp", "punch"],
    "Reverb": ["small", "big", "mix", "real"],
    "Amplitude": ["clip", "volume"],
    "Stereo": ["stereo"]
}



def save_summary_to_csv(summary, summary_multi, out_path="resultsummary.csv"):
    # Merge both dictionaries into rows
    all_rows = []

    # Regular metrics
    for degradation, stats in summary.items():
        row = {"degradation": degradation}
        row.update(stats)
        all_rows.append(row)

    # Multi-metrics
    for degradation, stats in summary_multi.items():
        row = {"degradation": degradation}
        row.update(stats)
        all_rows.append(row)

    # Get all unique column names
    all_keys = set()
    for row in all_rows:
        all_keys.update(row.keys())
    fieldnames = ["degradation"] + sorted(k for k in all_keys if k != "degradation")

    # Write to CSV
    with open(out_path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(all_rows)

    print(f"âœ… Summary saved to: {out_path}")


def modulation_spectrum_distance(x1, x2, fs=44100, n_fft=1024, hop_length=512, n_mod_bins=20):
    """
    Modulation Spectrum Distance for detecting excess reverb between two signals.
    """
    def get_modulation_spectrum(x):
        f, t, Zxx = stft(x, fs=fs, nperseg=n_fft, noverlap=n_fft - hop_length)
        mag = np.abs(Zxx)

        mod_spec = []
        for band in mag:
            envelope = band - np.mean(band)
            spectrum = np.abs(np.fft.fft(envelope))[:n_mod_bins]
            mod_spec.append(spectrum)

        mod_spec = np.array(mod_spec)
        mod_spec /= np.linalg.norm(mod_spec) + 1e-10
        return mod_spec.flatten()

    mod1 = get_modulation_spectrum(x1)
    mod2 = get_modulation_spectrum(x2)

    return euclidean(mod1, mod2)

def rms_energy(signal):
    return np.sqrt(np.mean(signal**2))

def spectral_flatness(y, sr):
    S = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))**2
    flatness = librosa.feature.spectral_flatness(S=S)
    return np.mean(flatness)


def stereo_energy_ratio(y_stereo):
    if y_stereo.ndim != 2 or y_stereo.shape[1] != 2:
        return 0.0  # mono or malformed input
    
    L = y_stereo[:, 0]
    R = y_stereo[:, 1]
    M = (L + R) / 2
    S = (L - R) / 2

    rms_M = np.sqrt(np.mean(M ** 2))
    rms_S = np.sqrt(np.mean(S ** 2))

    return rms_S / (rms_M + 1e-10)




def estimate_rt60(audio, sr=44100, energy_threshold_db=60):
    """
    Estimate RT60 using Schroeder integration of the energy decay curve.
    Returns RT60 in seconds or None if not estimable.
    """
    # Square the signal to get energy envelope
    energy = audio ** 2

    # Integrate backwards (Schroeder)
    decay_curve = np.cumsum(energy[::-1])[::-1]

    # Convert to dB (add small epsilon to avoid log(0))
    decay_db = 10.0 * np.log10(decay_curve + 1e-10)
    decay_db -= np.max(decay_db)  # normalize peak to 0 dB

    # Find where decay crosses -5 dB and -35 dB (or adjust window)
    try:
        t = np.arange(len(decay_db)) / sr
        start_idx = np.where(decay_db <= -5)[0][0]
        end_idx   = np.where(decay_db <= -35)[0][0]
    except IndexError:
        return None  # insufficient decay in the signal

    # Fit a line to the decay slope
    x = t[start_idx:end_idx]
    y = decay_db[start_idx:end_idx]
    slope, intercept = np.polyfit(x, y, 1)

    if slope >= 0:
        return None  # not decaying

    rt60 = -60.0 / slope
    return rt60

# def estimate_rt60(audio, sr):
#     try:
#         rt60 = pra.experimental.rt60.schroeder(audio, fs=sr)
#         return rt60
#     except Exception as e:
#         print(f"RT60 estimation failed: {e}")
#         return None


def dynamic_range_std(audio, frame_length=2048, hop_length=1024):
    frames = librosa.util.frame(audio, frame_length=frame_length, hop_length=hop_length)
    rms = np.sqrt(np.mean(frames**2, axis=0))
    return np.std(rms)


def transient_strength(y, sr):
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)
    return np.mean(onset_env)


def multiband_spectral_profile(y, sr, bands):
    S = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))**2
    freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)
    profile = []

    for low, high in bands:
        band = np.logical_and(freqs >= low, freqs < high)
        energy = np.sum(S[band, :])
        profile.append(energy)

    profile = np.array(profile)
    return profile / (np.sum(profile) + 1e-10)  # Normalize to unit sum


def spectral_balance_metrics(clean, degraded, output, sr=44100):
    bands = [
        (20, 60), (60, 250), (250, 500), (500, 2000),
        (2000, 4000), (4000, 6000), (6000, 10000),
        (10000, 16000), (16000, 20000)
    ]

    p_clean = multiband_spectral_profile(clean, sr, bands)
    p_degr = multiband_spectral_profile(degraded, sr, bands)
    p_out  = multiband_spectral_profile(output, sr, bands)

    # Compute distance metrics
    cos_degr = cosine(p_clean, p_degr)
    cos_out  = cosine(p_clean, p_out)
    euc_degr = euclidean(p_clean, p_degr)
    euc_out  = euclidean(p_clean, p_out)

    # Use shared improvement logic
    cos_stats = compute_improvement(0, cos_degr, cos_out)  # 0 = perfect match
    euc_stats = compute_improvement(0, euc_degr, euc_out)

    return {
        "cosine": {
            "distance_degraded": cos_degr,
            "distance_output": cos_out,
            **cos_stats
        },
        "euclidean": {
            "distance_degraded": euc_degr,
            "distance_output": euc_out,
            **euc_stats
        }
    }


def load_audio(filepath, sr=44100, mono=True):
    y, orig_sr = sf.read(filepath)
    if orig_sr != sr:
        y = librosa.resample(y.T, orig_sr=orig_sr, target_sr=sr).T  # handle stereo resampling
    if mono and y.ndim == 2:
        y = np.mean(y, axis=1)
    return y


# === BAND ENERGY METRIC ===
def band_energy_ratio(y, sr, band_low, band_high, n_fft=2048, hop_length=512):
    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))**2
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    band = np.logical_and(freqs >= band_low, freqs < band_high)
    band_energy = np.sum(S[band, :])
    total_energy = np.sum(S)
    return band_energy / (total_energy + 1e-10)


def compute_improvement(clean, degraded, output):
    err_before = clean - degraded
    err_after = clean - output

    abs_before = abs(err_before)
    abs_after = abs(err_after)

    rel_improvement = (abs_before - abs_after) / (abs_before + 1e-10)
    percent_recovered = 100.0 * (1.0 - abs_after / (abs_before + 1e-10))
    improved = abs_after < abs_before

    rel_error_degraded = abs_before / (abs(clean) + 1e-10)
    rel_error_output   = abs_after / (abs(clean) + 1e-10)

    return {
        "abs_error_before": abs_before,
        "abs_error_after": abs_after,
        "error_before": err_before,
        "error_after": err_after,
        "rel_improvement": rel_improvement,
        "percent_recovered": percent_recovered,
        "rel_error_degraded": rel_error_degraded,
        "rel_error_output": rel_error_output,
        "improved": improved
    }


# === SAMPLE EVALUATION ===
def evaluate_sample(clean, degraded, output, degradations, clean_stereo, degraded_stereo, output_stereo):
    results = {}

    
    for deg in degradations:
        if deg in ["clarity", "bright", "dark", "airy", "warm", "boom", "mud", "vocal"]:
            band_low, band_high = {
                "clarity": (4000, SR // 2),
                "bright":  (6000, SR // 2),
                "dark":    (6000, SR // 2),
                "airy":    (10000, SR // 2),
                "warm":    (20, 400),
                "boom":    (20, 150),
                "mud":    (200, 500),
                "vocal":    (350, 3500),
            }[deg]

            clean_val = band_energy_ratio(clean, SR, band_low, band_high)
            degr_val = band_energy_ratio(degraded, SR, band_low, band_high)
            out_val = band_energy_ratio(output, SR, band_low, band_high)

            stats = compute_improvement(clean_val, degr_val, out_val)

            results[deg] = {
                "ratio_clean": clean_val,
                "ratio_degr": degr_val,
                "ratio_out": out_val,
                **stats
            }


        if deg in ["xband", "mic"]:
            metrics = spectral_balance_metrics(clean, degraded, output, sr=44100)

            results[deg] = {
                "cosine_clean": 0.0,  # perfect alignment = 0
                "cosine_degraded": metrics["cosine"]["distance_degraded"],
                "cosine_output": metrics["cosine"]["distance_output"],
                "cosine_abs_error_before": metrics["cosine"]["abs_error_before"],
                "cosine_abs_error_after": metrics["cosine"]["abs_error_after"],
                "cosine_rel_error_degraded": metrics["cosine"]["rel_error_degraded"],
                "cosine_rel_error_output": metrics["cosine"]["rel_error_output"],
                "cosine_percent_recovered": metrics["cosine"]["percent_recovered"],
                "cosine_rel_improvement": metrics["cosine"]["rel_improvement"],
                "cosine_improved": metrics["cosine"]["improved"],

                "euclidean_clean": 0.0,
                "euclidean_degraded": metrics["euclidean"]["distance_degraded"],
                "euclidean_output": metrics["euclidean"]["distance_output"],
                "euclidean_abs_error_before": metrics["euclidean"]["abs_error_before"],
                "euclidean_abs_error_after": metrics["euclidean"]["abs_error_after"],
                "euclidean_rel_error_degraded": metrics["euclidean"]["rel_error_degraded"],
                "euclidean_rel_error_output": metrics["euclidean"]["rel_error_output"],
                "euclidean_percent_recovered": metrics["euclidean"]["percent_recovered"],
                "euclidean_rel_improvement": metrics["euclidean"]["rel_improvement"],
                "euclidean_improved": metrics["euclidean"]["improved"]
            }


        if deg in ["small", "big", "mix", "real"]:
            rt_clean = estimate_rt60(clean, sr)
            rt_degr = estimate_rt60(degraded, sr)
            rt_out  = estimate_rt60(output, sr)

            if None not in [rt_clean, rt_degr, rt_out]:
                rt_stats = compute_improvement(rt_clean, rt_degr, rt_out)
            else:
                rt_stats = {
                    "abs_error_before": np.nan,
                    "abs_error_after": np.nan,
                    "rel_improvement": np.nan,
                    "percent_recovered": np.nan,
                    "rel_error_degraded": np.nan,
                    "rel_error_output": np.nan,
                    "improved": False
                }

            try:
                msd_degr = modulation_spectrum_distance(clean, degraded, fs=sr)
                msd_out  = modulation_spectrum_distance(clean, output, fs=sr)
                msd_stats = compute_improvement(0.0, msd_degr, msd_out)
            except Exception as e:
                print(f"MSD failed for {deg}: {e}")
                msd_degr = np.nan
                msd_out = np.nan
                msd_stats = {
                    "abs_error_before": np.nan,
                    "abs_error_after": np.nan,
                    "rel_improvement": np.nan,
                    "percent_recovered": np.nan,
                    "rel_error_degraded": np.nan,
                    "rel_error_output": np.nan,
                    "improved": False
                }

            results[deg] = {
                "rt_clean": rt_clean,
                "rt_degraded": rt_degr,
                "rt_output": rt_out,
                **{f"rt60_{k}": v for k, v in rt_stats.items()},  # prefix for clarity

                "modspec_dist_degraded": msd_degr,
                "modspec_dist_output": msd_out,
                **{f"msd_{k}": v for k, v in msd_stats.items()}  # also prefixed
            }


        if deg == "volume":
            rms_clean = rms_energy(clean)
            rms_degr = rms_energy(degraded)
            rms_out  = rms_energy(output)


            stats = compute_improvement(rms_clean, rms_degr, rms_out)


            results[deg] = {
                "rms_clean": rms_clean,
                "rms_degraded": rms_degr,
                "rms_output": rms_out,
                **stats
            }


        if deg == "clip":
            sf_clean = spectral_flatness(clean, sr)
            sf_degr = spectral_flatness(degraded, sr)
            sf_out  = spectral_flatness(output, sr)



            stats = compute_improvement(sf_clean, sf_degr, sf_out)

            results[deg] = {
                "flatness_clean": sf_clean,
                "flatness_degraded": sf_degr,
                "flatness_output": sf_out,
                **stats
            }


        if deg == "stereo":

            r_clean = stereo_energy_ratio(clean_stereo)
            r_degr = stereo_energy_ratio(degraded_stereo)
            r_out  = stereo_energy_ratio(output_stereo)


            stats = compute_improvement(r_clean, r_degr, r_out)


            results[deg] = {
                "stereo_clean": r_clean,
                "stereo_degraded": r_degr,
                "stereo_output": r_out,
                **stats
            }

        if deg == "comp":
            dyn_clean = dynamic_range_std(clean)
            dyn_degr = dynamic_range_std(degraded)
            dyn_out  = dynamic_range_std(output)


            stats = compute_improvement(dyn_clean, dyn_degr, dyn_out)

            results[deg] = {
                "dyn_clean": dyn_clean,
                "dyn_degraded": dyn_degr,
                "dyn_output": dyn_out,
                **stats
            }




        if deg == "punch":
            ts_clean = transient_strength(clean, sr)
            ts_degr = transient_strength(degraded, sr)
            ts_out  = transient_strength(output, sr)




            stats = compute_improvement(ts_clean, ts_degr, ts_out)

            results[deg] = {
                "transient_clean": ts_clean,
                "transient_degraded": ts_degr,
                "transient_output": ts_out,
                **stats
            }

    return results


def summarize_metrics(metrics_by_degradation):
    summary = {}
    summary_multi = {}

    # Set of degradations that have multiple sub-metrics (like reverb types)
    multi_metric_degradations = {"mic", "xband", "small", "big", "mix", "real"}

    for degradation, entries in metrics_by_degradation.items():
        if not entries:
            continue

        if degradation in multi_metric_degradations:
            multi_keys = list(entries[0].keys())
            multi_summary = {}

            for k in multi_keys:
                vals = [x[k] for x in entries]
                if isinstance(vals[0], (int, float, np.number, bool, np.bool_)):
                    avg_val = np.mean(vals)
                    if isinstance(vals[0], (bool, np.bool_)):
                        avg_val = 100.0 * avg_val  # percent
                    multi_summary[f"avg_{k}"] = avg_val

            multi_summary["n_samples"] = len(entries)
            summary_multi[degradation] = multi_summary

        else:
            abs_before = [x["abs_error_before"] for x in entries]
            abs_after = [x["abs_error_after"] for x in entries]
            err_before = [x["error_before"] for x in entries]
            err_after = [x["error_after"] for x in entries]
            rel_improvement = [x["rel_improvement"] for x in entries]
            pct_recovered = [x["percent_recovered"] for x in entries]
            improved = [x["improved"] for x in entries]
            rel_error_degraded = [x["rel_error_degraded"] for x in entries]
            rel_error_output = [x["rel_error_output"] for x in entries]


            summary[degradation] = {
                "n_samples": len(entries),
                "avg_abs_error_before": np.mean(abs_before),
                "avg_abs_error_after": np.mean(abs_after),
                "avg_error_before": np.mean(err_before),
                "std_error_before": np.std(err_before),
                "avg_error_after": np.mean(err_after),
                "std_error_after": np.std(err_after),
                "avg_rel_error_degraded": np.mean(rel_error_degraded),
                "avg_rel_error_output": np.mean(rel_error_output),
                "avg_rel_improvement": np.mean(rel_improvement),
                "avg_percent_recovered": np.mean(pct_recovered),
                "percent_improved": 100.0 * np.mean(improved)
            }

    return summary, summary_multi


def flatten_control_summary(summary, summary_multi, folder_name):
    rows = []
    for degradation, metrics in summary.items():
        row = {"folder": folder_name, "degradation": degradation}
        row.update(metrics)
        rows.append(row)

    for degradation, metrics in summary_multi.items():
        row = {"folder": folder_name, "degradation": degradation}
        row.update(metrics)
        rows.append(row)

    return rows


def run_control_evaluation(jsonl_path, folders, clean_targets_root=None, degraded_root=None, excel_output=None, save_excel=True):
    all_rows = []
    for folder in folders:
        print(f"\nðŸš€ Running evaluation for: {folder}")
        summary, summary_multi = process_jsonl(jsonl_path, folder, clean_targets_root, degraded_root)
        folder_name = os.path.basename(folder)
        all_rows.extend(flatten_control_summary(summary, summary_multi, folder_name))

    df = pd.DataFrame(all_rows)
    if save_excel and excel_output and not df.empty:
        Path(excel_output).parent.mkdir(parents=True, exist_ok=True)
        with pd.ExcelWriter(excel_output) as writer:
            for folder, group_df in df.groupby("folder"):
                sheet_name = folder[:31]
                group_df.drop(columns=["folder"], errors="ignore").to_excel(writer, sheet_name=sheet_name, index=False)
        print(f"\nâœ… All attribute results saved to Excel: {excel_output}")

    return df



# === MAIN PROCESSING LOOP ===
def process_jsonl(jsonl_path, output_dir, clean_targets_root=None, degraded_root=None):
    metrics_by_degradation = defaultdict(list)
    fs=44100
    i=0
    
    print(f"Debug: clean_targets_root={clean_targets_root}, degraded_root={degraded_root}, output_dir={output_dir}")
    
    with open(jsonl_path, "r") as f:
        for line in tqdm(f):
            entry = json.loads(line)
            audio_id = entry.get("id")
            original_id = entry.get("original_id")
            degradations = entry.get("degradations", [])
            if degradations is None:
                print(f"âš ï¸âš ï¸âš ï¸ Skipping entry with null degradations: {audio_id}")
                continue

            # Handle missing original_id by using audio_id directly (files have matching names in both folders)
            if original_id is None:
                original_id = audio_id

            # Construct file paths from folders
            clean_path = os.path.join(clean_targets_root, f"{original_id}.flac") if clean_targets_root else None
            degraded_path = os.path.join(degraded_root, f"{original_id}.flac") if degraded_root else None
            output_path = os.path.join(output_dir, f"{audio_id}.flac")

            # Check if all required files exist
            missing_files = []
            if clean_path and not os.path.exists(clean_path):
                missing_files.append(f"clean: {clean_path}")
            if degraded_path and not os.path.exists(degraded_path):
                missing_files.append(f"degraded: {degraded_path}")
            if not os.path.exists(output_path):
                missing_files.append(f"output: {output_path}")
            
            if missing_files:
                if i < 3:  # Print first 3 missing files for debugging
                    print(f"Missing files for {audio_id}: {', '.join(missing_files)}")
                continue



            # if len(degradations)>1:
            #     print("skipped",len(degradations))
            #     continue

            # if len(degradations)<2:
            #     print("skipped",len(degradations))
            #     continue
            
            clean_stereo, degraded_stereo, output_stereo = None, None, None
            # mono=True
            if "stereo" in degradations:
                # mono=False
                clean_stereo = load_audio(clean_path,fs,mono=False)
                degraded_stereo = load_audio(degraded_path,fs,mono=False)
                output_stereo = load_audio(output_path,fs,mono=False)

            try:
                clean = load_audio(clean_path,fs,mono=True)
                degraded = load_audio(degraded_path,fs,mono=True)
                output = load_audio(output_path,fs,mono=True)
            except Exception as e:
                print(f"Failed to load audio for {audio_id}: {e}")
                continue

            result = evaluate_sample(clean, degraded, output, degradations, clean_stereo, degraded_stereo, output_stereo)

            for degradation, metrics in result.items():
                metrics_by_degradation[degradation].append(metrics)

            print(i)
            i+=1
            # if i==200:
            #     break

    for k, v in metrics_by_degradation.items():
        print(f"{k}: {len(v)} entries")

    summary, summary_multi = summarize_metrics(metrics_by_degradation)

    return summary, summary_multi


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Compute control metrics for inference outputs")
    parser.add_argument("--jsonl-path", default="/testset_pt.jsonl")
    parser.add_argument(
        "--folders",
        nargs="+",
        default=["outputs/run1", "outputs/run2"],
        help="Paths to inference output folders"
    )
    parser.add_argument("--excel-output", default="/evaluation/control/attribute_metrics_all.xlsx")
    parser.add_argument("--skip-excel", action="store_true", help="Do not write the Excel summary")
    args = parser.parse_args()
    run_control_evaluation(args.jsonl_path, args.folders, excel_output=args.excel_output, save_excel=not args.skip_excel)
